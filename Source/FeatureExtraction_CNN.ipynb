{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports!\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import resize\n",
    "from skimage import io, data, color, exposure\n",
    "import pandas as pd\n",
    "import csv\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../train_photo_to_biz_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_img = [os.listdir(\"../train_photos/\")]\n",
    "# image_root = \"../train_photos/\"\n",
    "# C:\\Users\\Shreyas\\Desktop\\RestaurantClassification\\train_photos\\train_photos\n",
    "train_img = [os.listdir(\"../train_photos/\")]\n",
    "image_root = \"../train_photos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns greyscale and resized image\n",
    "def get_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    \n",
    "    if img is not None:\n",
    "        img_resize = cv2.resize(img, (299,299))\n",
    "        return img_resize\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://code.oursky.com/tensorflow-svm-image-classifications-engine/\n",
    "def create_graph(model_path):\n",
    "    \"\"\"\n",
    "    create_graph loads the inception model to memory, should be called before\n",
    "    calling extract_features.\n",
    " \n",
    "    model_path: path to inception model in protobuf form.\n",
    "    \"\"\"\n",
    "    with gfile.FastGFile(model_path, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "create_graph(\"../Inception V3/tensorflow_inception_graph.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting the bottleneck feature using CNN \n",
    "\n",
    "def get_feature(image_path):\n",
    "    feature_dimension = 2048\n",
    "    with tf.Session() as sess:\n",
    "            flattened_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "            ph = tf.placeholder(tf.string, shape=[])\n",
    "            image_data = get_image(image_path)\n",
    "            image_data = np.array(image_data)\n",
    "            image_data = np.expand_dims(image_data,axis=0)\n",
    "            feature = sess.run(flattened_tensor, {\n",
    "                'Mul:0':  image_data\n",
    "            })\n",
    "            return np.squeeze(feature)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting features in batches. This should be faster\n",
    "def get_feature_from_list(image_path_list):\n",
    "    feature_dimension = 2048\n",
    "    features = np.empty((len(image_path_list), feature_dimension))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "            flattened_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "            for i, image_path in enumerate(image_path_list):\n",
    "                image_data = get_image(image_path)\n",
    "                image_data = np.array(image_data)\n",
    "                image_data = np.expand_dims(image_data,axis=0)\n",
    "                feature = sess.run(flattened_tensor, {\n",
    "                    'Mul:0':  image_data\n",
    "                })\n",
    "                features[i, :] = np.squeeze(feature)\n",
    "                \n",
    "    return features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility to print count\n",
    "def printCount(cnt):\n",
    "    if cnt==10:\n",
    "        print(\"10 images done!\")\n",
    "    elif cnt ==100:\n",
    "        print(\"100 images done!\")\n",
    "    elif cnt ==500:\n",
    "        print(\"500 images done!\")\n",
    "    elif cnt == 1000:\n",
    "        print(\"1000 images done!\")\n",
    "    elif cnt%10000 == 0:\n",
    "        print(str(cnt)+\" Images Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 Images Done!\n",
      "20000 Images Done!\n",
      "30000 Images Done!\n",
      "40000 Images Done!\n",
      "50000 Images Done!\n",
      "60000 Images Done!\n",
      "70000 Images Done!\n",
      "80000 Images Done!\n",
      "90000 Images Done!\n",
      "100000 Images Done!\n",
      "110000 Images Done!\n",
      "120000 Images Done!\n",
      "130000 Images Done!\n",
      "140000 Images Done!\n",
      "150000 Images Done!\n",
      "160000 Images Done!\n",
      "170000 Images Done!\n",
      "180000 Images Done!\n",
      "190000 Images Done!\n",
      "200000 Images Done!\n",
      "210000 Images Done!\n",
      "220000 Images Done!\n",
      "230000 Images Done!\n"
     ]
    }
   ],
   "source": [
    "# Extract feature for all images\n",
    "img_features = []\n",
    "batch_size = 10000\n",
    "# Start processing the images\n",
    "with open(r\"../train_data/train_feature_CNN.csv\", \"w\") as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter =\",\",quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow([\"imageid\", \"features\"])\n",
    "    \n",
    "    image_path_list = []\n",
    "    image_id_list = []\n",
    "    cnt = 0\n",
    "    for imageid in data['photo_id']:\n",
    "        img_path = image_root + str(imageid) + \".jpg\"\n",
    "        image_path_list.append(img_path)\n",
    "        image_id_list.append(imageid)\n",
    "        # Start batch processing\n",
    "        if(len(image_path_list) == batch_size):\n",
    "            img_features = get_feature_from_list(image_path_list)\n",
    "            for image_id, feature in enumerate(img_features):\n",
    "                writer.writerow([image_id_list[image_id], feature.tolist()])\n",
    "            \n",
    "            cnt+=batch_size\n",
    "            printCount(cnt)\n",
    "            image_id_list = []\n",
    "            image_path_list = []\n",
    "#     If some more images are left\n",
    "    if(len(image_path_list)> 0):\n",
    "            img_features = get_feature_from_list(image_path_list)\n",
    "            #print(img_features.shape)\n",
    "            for image_id, feature in enumerate(img_features):\n",
    "                #print(\"writing imageid\"+ str(image_id_list[image_id]))\n",
    "                writer.writerow([image_id_list[image_id], feature.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
